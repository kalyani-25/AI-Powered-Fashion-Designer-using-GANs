{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalyanivaidya/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Script started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV from: /Users/kalyanivaidya/AI Fashion Designer/data/DeepFashion2/paired_data.csv\n",
      "CSV loaded. Number of pairs: 191961\n",
      "Number of sketch paths: 191961\n",
      "Number of original paths: 191961\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/Users/kalyanivaidya/AI Fashion Designer/data/DeepFashion2/paired_data.csv\"\n",
    "print(\"Loading CSV from:\", csv_path)\n",
    "\n",
    "pairs_df = pd.read_csv(csv_path)\n",
    "print(\"CSV loaded. Number of pairs:\", len(pairs_df))\n",
    "\n",
    "sketch_paths = pairs_df['sketch'].tolist()\n",
    "original_paths = pairs_df['original'].tolist()\n",
    "print(\"Number of sketch paths:\", len(sketch_paths))\n",
    "print(\"Number of original paths:\", len(original_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(256, 256), channels=3):\n",
    "    print(\"Processing image:\", image_path)\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=channels)\n",
    "    image = tf.image.resize(image, target_size)\n",
    "    image = (image / 127.5) - 1.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(sketch_path, original_path):\n",
    "    sketch = load_and_preprocess_image(sketch_path, target_size=(256, 256), channels=1)\n",
    "    original = load_and_preprocess_image(original_path, target_size=(256, 256), channels=3)\n",
    "    return sketch, original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created from file paths.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((sketch_paths, original_paths))\n",
    "print(\"Dataset created from file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Processing image: Tensor(\"args_1:0\", shape=(), dtype=string)\n",
      "Mapping function applied to dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda sketch, orig: load_pair(sketch, orig),\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "print(\"Mapping function applied to dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset batched, limited, and prefetched.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.take(1)\n",
    "dataset = dataset.prefetch(1)\n",
    "print(\"Dataset batched, limited, and prefetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over dataset...\n",
      "Sketch batch shape: (4, 256, 256, 1)\n",
      "Original batch shape: (4, 256, 256, 3)\n",
      "Dataset processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 16:02:14.334086: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(\"Iterating over dataset...\")\n",
    "for sketches, originals in dataset:\n",
    "    print(\"Sketch batch shape:\", sketches.shape)\n",
    "    print(\"Original batch shape:\", originals.shape)\n",
    "\n",
    "print(\"Dataset processing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
